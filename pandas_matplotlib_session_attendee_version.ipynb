{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and Matplotlib Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This session, we will cover the basics of Pandas and Matplotlib - two packages used to manipulate, analyse and visualise data. The content herein aims to act as an introduction to Pandas/Matplotlib and is by no means exhastive. Refering to the [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) and [Matplotlib](https://matplotlib.org/index.html) documentation is an excellent way to extend your knowledge of these two modules and find answers to edge cases.\n",
    "\n",
    "___\n",
    "\n",
    "Let's start by importing the modules required for the session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this session, you will need the data set named ```pdb_data_no_dups.csv```, which can be downloaded from our [GitHub repository](https://github.com/IC-Computational-Biology-Society/Pandas_Matplotlib_session.git) dedicated to today's workshop. Make sure you save it in the same directory as this Jupyter notebook. \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a Python module, underpinned by Numpy, that enables efficient handling of tabular data structures, which are stored as DataFrame objects. These can either be created within a Python script or imported from separate files such as CSVs or Excel spreadsheets. \n",
    "\n",
    "Here, we will be working with a data set on summary protein structure determination informaiton taken from [Kaggle](https://www.kaggle.com/shahir/protein-data-set) to introduce basic Pandas commands.\n",
    "\n",
    "We will start by importing the data set into this Jupyter notebook and assigning it as a DataFrame to the variable ```df```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pdb_data_no_dups.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```.columns``` returns an array of column names from the DataFrame. Let's apply this to our ```df``` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Convert the array of columns into a list and assign it to a Python variable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 1 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "The top five rows of of the Pandas DataFrame can be returned by using the method ```.head()```. Run ```.head()``` on your ```df``` to get a brief insight to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```.index``` can give you some information on the number of entries in the DataFrame. Apply this method to your DataFrame. Is the result useful?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Determine the number of rows (entries) in your ```df``` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 2 ### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "DataFrames are typically structured with a single Python data type assigned to each column. In other words, columns containing numeric data should not include strings (e.g. 1, 2, 3, 'four' is not good practice). What Python function is used to return the data type of the variable's below? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_string = 'Hello_world'\n",
    "example_integer = 1234\n",
    "example_float = 1.234\n",
    "\n",
    "### Enter code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows you to check the data type contained within a column using the method ```.dtype```. Apply this to your DataFrame. Are the results what you would expect considering your previous insight into the DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful feature of Pandas is the ability to find all the unique values contained within a column. Squre brackets ```[]``` are used to slice a DataFrame into a single column and the method ```.unique()``` returns non-duplicate values. Run the cell below to see what the code returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experimentalTechnique'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 \n",
    "What types of macromolecules are included in your DataFrame?\n",
    "\n",
    "How could you clean this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "As well as returning unique entries in a column, we can find their frequencies using the method ```.value_counts()```. \n",
    "\n",
    "### Task 4 \n",
    "\n",
    "Apply ```.value_counts()``` to an appropriate column of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 4 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Often, we only want to work with numeric data from a DataFrame. Columns containing strings can confound analysis if they are not removed. We can create a new DataFrame that countains only floats and integers using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame copy made of df, containing only integers and floats.  \n",
    "df_numeric = df.select_dtypes(include = [\"int64\", \"float64\"])\n",
    "\n",
    "# Displaying new DataFrame. \n",
    "df_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "Modify the code above to create a copy of ```df``` that contains only string-type data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 5 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "A quick summary of numeric data within a DataFrame can be obtained using the method ```.describe()```. Apply this to your ```df```. Ask your supervisor how you can transpose the DataFrame to move your summary statistics returned by ```.describe()``` to the column position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major problem that arises when working with unfamiliar data sets is the insertion of ```NULL```, ```Na``` or ```NaN``` values. Rows with any of these values can be removed using the ```.dropna()``` method. \n",
    "\n",
    "How many entries of your original ```df``` DataFrame are free from missing values for all parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the presence of missing values in a DataFrame affect summary statistics? Write some code in the cell below to test your hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code below \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "The final feature Pandas we will look at is boolean operators. The method ```.iloc[]``` will return the entry at a given index. A further argument can be parsed into ```.iloc[]``` to return both the entry at a given index and that entry's parameter value at a given column. Pandas, like Python, uses a starting index of ```0```. Run the code below to see ```.iloc[]``` in action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_two = df.iloc[1]                   # Returns the entire entry from the second column\n",
    "\n",
    "entry_three_column_four = df.iloc[2, 3]  # Returns the single value in row 3, column 4\n",
    "\n",
    "print(entry_two)\n",
    "print('-------')                         # Arbitrary seperator\n",
    "print(entry_three_column_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful method is ```.loc[]```. It works in a similar way to ```.iloc[]``` but is used as a logical entry selector. Boolean operators are used with ```.loc[]``` to exclusively select entries based on values in a specified column. Run the code below to get a feel for ```.loc[]```.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only entries solved by X-ray diffraction and assign to new DataFrame\n",
    "xray_structures = df.loc[df['experimentalTechnique'] == 'X-RAY DIFFRACTION']\n",
    "\n",
    "# Select only entries solved by X-ray diffraciton and are DNA-based\n",
    "dna_xray_structures = df.loc[(df['experimentalTechnique'] == 'X-RAY DIFFRACTION') & (df['classification'] == 'DNA')]\n",
    "\n",
    "# Shows the DataFrame contains only one unique entry in the 'experimentalTechnique' field. \n",
    "xray_structures['experimentalTechnique'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the second variable is defined using the element-wise boolean operator ```&```. The element-wise booleans in Pandas for AND, OR and XOR are ```&```, ```|``` and ```^```, respectively. \n",
    "\n",
    "\n",
    "It is good practice to use ```.loc[]``` to conditionally select entries from DataFrames but can be omitted, giving the same result. \n",
    "\n",
    "\n",
    "### Task 6 \n",
    "\n",
    "What year was the 100th protein structure (```macromoleculeType```) solved solely by ```ELECTRON MICROSCOPY```?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Task 6 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib introduction\n",
    "\n",
    "This section will introduce some of the basics of Maplotlib. It is by no means an exhaustive overview of the package and you should look through the [Matplotlib documentation](https://matplotlib.org/) when working on your own projects in the future. \n",
    "\n",
    "The terminology of Matplotlib can cause confusion for those unfamiliar with the package. The term ***figure*** refers to the entire plot area of a graph, which i sseparate from the plot area. An ***axis*** is placed onto the Matplotlib *figure* and defines the area onto which your data will be plotted. A Matplotlib *axis*, ambiguously, includes both x- and y-axes. Multiple *axes* can be plotted onto a single figure. \n",
    "\n",
    "Let's start by plotting a histogram of the resolution data in the DataFrame. By doing so, we can get an insight into how the data is distributed. \n",
    "\n",
    "Run the code below. What does each line do? Speak with your supervisor for clarification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising figure as a 1x1 grid of axes\n",
    "resolution_fig, ax_res_hist = plt.subplots(1, 1)   \n",
    "\n",
    " # Define number, size and range of bins\n",
    "res_bins = np.arange(0, 5, 0.2)                   \n",
    "\n",
    "# Plot histogram of non-NaN resolution data using Pandas\n",
    "ax_res_hist.hist(df['resolution'].dropna(),        \n",
    "                 bins=res_bins\n",
    "                )\n",
    "\n",
    "plt.show()         # Displays all axes on figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "Plot a histogram for a numerical parameter from ```df``` of your chioce. Inspect the [Maplotlib documentation](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.hist.html?highlight=hist#matplotlib.axes.Axes.hist) for this form of histogram and add additional arguments into your code to format the graph's appearance. \n",
    "\n",
    "Axes labels can also be added using the method ```.set_nlabel```, replacing ```n``` with either ```x``` or ```y```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 7 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Scatter plots can be a good way to identify trends or groups within data. \n",
    "\n",
    "Run the code below. Is it valid to say the resolution of solved macromolecules has been worsening over time? What reasons are there for the trends observed? Discuss with your supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise figure with 1x1 grid of axes\n",
    "res_year_fig, res_year_ax = plt.subplots(1, 1)   \n",
    "\n",
    "''' Remove only NaN/NULL values from the resolution and publicationYear columns and\n",
    "return a DataFrame with only these two columns, saving computer memory '''\n",
    "\n",
    "year_resolution_df = df.dropna(subset=['resolution', 'publicationYear'])[['resolution', 'publicationYear']]\n",
    "\n",
    "res_year_ax.scatter(year_resolution_df['publicationYear'],   # Plot x-axis data\n",
    "                    year_resolution_df['resolution']         # Plot y-axis data\n",
    "                   )\n",
    "\n",
    "plt.show()   # Display figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "\n",
    "Repurpose the code above to plot *resolution* as a function of *molecular weight*. \n",
    "\n",
    "Refer to the [Matplotlib documentation](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.scatter.html?highlight=scatter#matplotlib.axes.Axes.scatter) for scatter plots and add some formatting to change the plot's appearance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 7 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "The final plot we will look at is the bar plot, specifically a horizontal bar plot. Run the code below. Discuss the code with your supervisor if anything is unlcear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the style of figure\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Initialise figure with 1x1 grid of axes\n",
    "fig, ax = plt.subplots(1, 1)   \n",
    "\n",
    "ax.barh(y=df['experimentalTechnique'].value_counts().index,   # Labels added to y-axis\n",
    "        width=df['experimentalTechnique'].value_counts(),     # Frequency added to x-axis\n",
    "        log=True         # The difference between frequencies spans several orders of magnitude. Using a semi-log scale makes the data easier to interpret here\n",
    "       )                 # Comment out 'log=True' to highlight its usefulness here. \n",
    "\n",
    "plt.show()   # Display figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8\n",
    "\n",
    "What is the most commonly soled type of macromolecule? Plot a bargraph to get your answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 8 ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
